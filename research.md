---
layout: page
title: Research
permalink: /research/
---

As humans, we can produce and understand words and sentences that we have never heard before, as long as we (and the words and sentences) play by the rules. For example, although we have specific expectations about what a given word should sound like, we do not require an exact physical copy, as a machine might, in order to recognize it. Nor do we fail to recognize a word if a person previously unknown to us produces it, or uses it in combination with a word we havenâ€™t heard before. Although we might learn a word in a given phrase or sentence context, or might tend to experience that word more often in one context than in another, we are by no means limited to recognizing or using that word only in that context, nor only in related contexts, nor only in the contexts that we have ever experienced it in.

As such, a marvellous expressive capacity is extended to us - the ability to generate and express formal structures that lead to contextually-specific compositional meanings.  This fact is particularly startling if you consider that human language is processed and generated by a biological organ whose general remit is to be driven by statistical regularities in its environment.  The human brain manifests a paradox when it comes to language: Despite the clear importance of statistical knowledge and distributional information during language use and language acquisition, our everyday language behaviors exemplify an ability to break free from the very (statistical) vice that bootstrapped us up into the realm of natural language users in the first place. While this capacity may seem pedestrian to us, it sets language apart from other perception-action systems and makes language behavior vexingly difficult to account for from a neuroscientist's and computationalist's point of view.

<img src="{{ base.url }}/assets/images/martinModel.png" alt="a compositional neural architecture for language" style="float: right; clear: right; padding: 1.5rem 1rem;"/>

One of the system properties that underlies this capacity in language is compositionality, whereby units or structures compose (and decompose) into meanings that are determined by the constituent parts and the rules used to combine them. The formal study of language has revealed the pantheon of linguistic forms that the systematicity of mind can take, and the last century has also seen astonishing progress in neuroscience and in artificial intelligence. But all this remarkable progress has yet to offer a satisfying explanation as to how the defining features of human language arise within the constraints of a neurophysiological system. Without an explanatory neurophysiological and computational account of the quintessential properties of human language - of hierarchical structure and domain, of function application and scope, and most definitely, of compositionality - our theories of language and the human mind and brain seem startlingly incomplete.
